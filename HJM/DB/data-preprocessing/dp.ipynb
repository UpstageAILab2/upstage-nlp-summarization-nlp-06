{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re \n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다.\n",
    "\n",
    "# visualization\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/NanumFont/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../../data\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"entity_name\",\n",
    "        \"project\": \"project_name\",\n",
    "        \"name\": \"name\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실험에서 쓰일 데이터를 load하여 데이터의 구조와 내용을 살펴보겠습니다.\n",
    "\n",
    "Train, dev, test 순서대로 12457, 499, 250개 씩 데이터가 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "display(train_df.tail())\n",
    "\n",
    "# dev data의 구조와 내용을 확인합니다.\n",
    "dev_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "display(dev_df.tail())\n",
    "\n",
    "# test data의 구조와 내용을 확인합니다.\n",
    "test_df = pd.read_csv(os.path.join(data_path,'test.csv'))\n",
    "display(test_df.tail())\n",
    "\n",
    "# train, dev, test 길이 확인\n",
    "print(train_df.shape[0], dev_df.shape[0], test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토픽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = train_df.groupby('topic')['summary'].aggregate(['count']).sort_values(by='count', ascending=False).reset_index()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=gb.iloc[:30], x='count', y='topic')#, palette='Set2')\n",
    "plt.title(f'토픽 (상위 30개)') # 토픽 전체 6527개\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Topic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특정 토픽별 대화 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일상 대화, 쇼핑, 전화 통화, 직업 면접, 음식 주문, 인터뷰, 길 묻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_topic(df, topic_name, idx):\n",
    "    \"\"\"\n",
    "    df : 데이터프레임 변수\n",
    "    topic_name : 특정 토픽 이름\n",
    "    idx : 확인하려는 개수\n",
    "    \"\"\"\n",
    "    cond = df[df['topic'] == topic_name]\n",
    "    a = cond['dialogue'].reset_index(drop=True)\n",
    "    b = cond['summary'].reset_index(drop=True)\n",
    "    # print(f'{topic_name}: {len(cond)}개')\n",
    "    for i in range(0, idx):\n",
    "        print(f'--- 대화 ---\\n{a[i]}')\n",
    "        print(f'--- 요약 ---\\n{b[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_topic(train_df, '길 묻기', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_length 설정 등을 위한 길이 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kobart-summarization 기준으로 확인\n",
    "dialogue_tokenizer = train_df['dialogue'].apply(lambda x: tokenizer(x))\n",
    "summary_tokenizer = train_df['summary'].apply(lambda x: tokenizer(x))\n",
    "topic_tokenizer = train_df['topic'].apply(lambda x: tokenizer(x))\n",
    "\n",
    "dialogue_len = dialogue_tokenizer.apply(lambda x: len(x['input_ids']))\n",
    "summary_len = summary_tokenizer.apply(lambda x: len(x['input_ids']))\n",
    "topic_len = topic_tokenizer.apply(lambda x: len(x['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description으로 대략적인 파악\n",
    "temp = dialogue_len.describe().reset_index()\n",
    "temp0 = summary_len.describe().reset_index()\n",
    "temp1 = topic_len.describe().reset_index()\n",
    "\n",
    "length_dsc = temp.merge(temp0, on='index').merge(temp1, on='index')\n",
    "length_dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot으로 분포 확인\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(data=dialogue_len.reset_index(), x=dialogue_len.index, y='dialogue')\n",
    "plt.title('대화 길이')\n",
    "plt.xlabel('Index')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(data=summary_len.reset_index(), x=summary_len.index, y='summary')\n",
    "plt.title('요약문 길이')\n",
    "plt.xlabel('Index')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(data=topic_len.reset_index(), x=topic_len.index, y='topic')\n",
    "plt.title('토픽 길이')\n",
    "plt.xlabel('Index')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화 길이보다 요약문 길이가 짧음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_len_list = dialogue_len.tolist()\n",
    "sum_len_list = summary_len.tolist()\n",
    "tpc_len_list = topic_len.tolist()\n",
    "\n",
    "for idx in range(0, train_df.shape[0]):\n",
    "    if dia_len_list[idx] <= sum_len_list[idx]:\n",
    "        print(idx, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화 길이는 800 밑으로 대거 분포해있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_len_800 = []\n",
    "sum_len_125 = []\n",
    "tpc_len_40 = []\n",
    "for idx in range(0, train_df.shape[0]):\n",
    "    if dia_len_list[idx] >= 800:\n",
    "        dia_len_800.append(idx)\n",
    "    if sum_len_list[idx] >= 125:\n",
    "        sum_len_125.append(idx)\n",
    "    if tpc_len_list[idx] >= 40:\n",
    "        tpc_len_40.append(idx)\n",
    "\n",
    "dia_800_df = train_df.loc[dia_len_800]\n",
    "sum_125_df = train_df.loc[sum_len_125]\n",
    "tpc_40_df = train_df.loc[tpc_len_40]\n",
    "\n",
    "print(dia_800_df.shape[0], sum_125_df.shape[0], tpc_40_df.shape[0])\n",
    "\n",
    "display(dia_800_df.head())\n",
    "display(sum_125_df.head())\n",
    "display(tpc_40_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dia_sum_check(df):\n",
    "    \"\"\"\n",
    "    df : 데이터프레임 변수\n",
    "    \"\"\"\n",
    "    # idx_list = df['fname'].apply(lambda x: int(x.split('_')[1])).tolist() # fname 잘 못 되어 있음\n",
    "    idx_list = df.reset_index()['index'].tolist()\n",
    "    for idx in idx_list:\n",
    "        print(f\"--- 대화 ---\\n{df['dialogue'].loc[idx]}\")\n",
    "        print(f\"--- 요약 ---\\n{df['summary'].loc[idx]}\\n\")\n",
    "\n",
    "dia_sum_check(dia_800_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = dia_800_df.groupby('topic')['summary'].aggregate(['count']).sort_values(by='count', ascending=False).reset_index()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=gb, x='count', y='topic')#, palette='Set2')\n",
    "plt.title(f'토픽')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Topic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약문 길이는 125 밑으로 대거 분포해있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_sum_check(sum_125_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = sum_125_df.groupby('topic')['summary'].aggregate(['count']).sort_values(by='count', ascending=False).reset_index()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=gb, x='count', y='topic')#, palette='Set2')\n",
    "plt.title(f'토픽')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Topic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토픽 길이는 대부분 20 이하인데, 40 이상인 토픽 3개가 존재함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_sum_check(tpc_40_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tpc_40_df.reset_index()['index'].tolist():\n",
    "    print(f\"{idx}. {tpc_40_df['topic'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 좌우 공백 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_strip = train_df['dialogue'].apply(lambda x: x.strip())\n",
    "summary_strip = train_df['summary'].apply(lambda x: x.strip())\n",
    "topic_strip = train_df['topic'].apply(lambda x: x.strip())\n",
    "\n",
    "dialogue_tokenizer_strip = dialogue_strip.apply(lambda x: tokenizer(x))\n",
    "summary_tokenizer_strip = summary_strip.apply(lambda x: tokenizer(x))\n",
    "topic_tokenizer_strip = topic_strip.apply(lambda x: tokenizer(x))\n",
    "\n",
    "dialogue_strip_len = dialogue_tokenizer_strip.apply(lambda x: len(x['input_ids']))\n",
    "summary_strip_len = summary_tokenizer_strip.apply(lambda x: len(x['input_ids']))\n",
    "topic_strip_len = topic_tokenizer_strip.apply(lambda x: len(x['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dialogue_strip_len.describe().reset_index()\n",
    "temp0 = summary_strip_len.describe().reset_index()\n",
    "temp1 = topic_strip_len.describe().reset_index()\n",
    "\n",
    "length_dsc = temp.merge(temp0, on='index').merge(temp1, on='index')\n",
    "display(length_dsc)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(data=dialogue_strip_len.reset_index(), x=dialogue_strip_len.index, y='dialogue')\n",
    "plt.title('대화 길이 (공백 제거)')\n",
    "plt.xlabel('Index')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(data=summary_strip_len.reset_index(), x=summary_strip_len.index, y='summary')\n",
    "plt.title('요약문 길이 (공백 제거)')\n",
    "plt.xlabel('Index')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(data=topic_strip_len.reset_index(), x=topic_strip_len.index, y='topic')\n",
    "plt.title('토픽 길이 (공백 제거)')\n",
    "plt.xlabel('Index')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자음이나 모음만으로 구성된 경우 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moeum_list = ['ㅏ', 'ㅓ', 'ㅗ', 'ㅜ', 'ㅡ', 'ㅣ', 'ㅐ', 'ㅔ', 'ㅚ', 'ㅟ', \n",
    "              'ㅑ', 'ㅕ', 'ㅛ', 'ㅠ', 'ㅒ', 'ㅖ', 'ㅘ', 'ㅙ', 'ㅝ', 'ㅞ', 'ㅢ']\n",
    "jaeum_list = ['ㄱ', 'ㄴ', 'ㄷ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅅ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', \n",
    "              'ㅌ', 'ㅍ', 'ㅎ', 'ㄲ', 'ㄸ', 'ㅃ', 'ㅆ', 'ㅉ']\n",
    "\n",
    "print('\\n# 대화에서 모음만으로 구성된 경우')\n",
    "print('---'*25)\n",
    "for moeum in moeum_list:\n",
    "    temp = train_df[train_df['dialogue'].apply(lambda x: x.find(moeum) != -1)]['dialogue']\n",
    "    if len(temp) > 0:\n",
    "        print(f'[{moeum}]')\n",
    "        print(temp)\n",
    "print('---'*25)\n",
    "\n",
    "print('\\n# 대화에서 자음만으로 구성된 경우')\n",
    "print('---'*25)\n",
    "for jaeum in jaeum_list:\n",
    "    temp = train_df[train_df['dialogue'].apply(lambda x: x.find(jaeum) != -1)]['dialogue']\n",
    "    if len(temp) > 0:\n",
    "        print(f'[{jaeum}]')\n",
    "        print(temp)\n",
    "print('---'*25)\n",
    "\n",
    "print('\\n# 요약문에서 모음만으로 구성된 경우')\n",
    "print('---'*25)\n",
    "for moeum in moeum_list:\n",
    "    temp = train_df[train_df['summary'].apply(lambda x: x.find(moeum) != -1)]['summary']\n",
    "    if len(temp) > 0:\n",
    "        print(f'[{moeum}]')\n",
    "        print(temp)\n",
    "print('---'*25)\n",
    "\n",
    "print('\\n# 요약문에서 자음만으로 구성된 경우')\n",
    "print('---'*25)\n",
    "for jaeum in jaeum_list:\n",
    "    temp = train_df[train_df['summary'].apply(lambda x: x.find(jaeum) != -1)]['summary']\n",
    "    if len(temp) > 0:\n",
    "        print(f'[{jaeum}]')\n",
    "        print(temp)\n",
    "print('---'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.loc[9677, 'dialogue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마스킹 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개인정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_masking(text):\n",
    "    pattern = r'#\\w+#'\n",
    "    masked = re.findall(pattern, text)\n",
    "    return masked\n",
    "\n",
    "masked_train = train_df['dialogue'].apply(lambda x: str(set(reg_masking(x))))\n",
    "for idx in range(0, train_df.shape[0]):\n",
    "    print(masked_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = masked_train.reset_index()\n",
    "temp_df['dialogue'] = temp_df['dialogue'].apply(lambda x: set(eval(x)))\n",
    "unique_dialogues = set().union(*temp_df['dialogue'])\n",
    "print(unique_dialogues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사람"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_person(text):\n",
    "    pattern = r'#\\w+\\d#'\n",
    "    masked = re.findall(pattern, text)\n",
    "    return masked\n",
    "\n",
    "masked_person = train_df['dialogue'].apply(lambda x: str(set(reg_person(x))))\n",
    "for idx in range(0, train_df.shape[0]):\n",
    "    print(masked_person[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = masked_person.reset_index()\n",
    "temp_df['dialogue'] = temp_df['dialogue'].apply(lambda x: set(eval(x)))\n",
    "unique_dialogues = set().union(*temp_df['dialogue'])\n",
    "print(unique_dialogues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좌우 공백 제거\n",
    "train_df['dialogue'] = train_df['dialogue'].apply(lambda x: x.strip())\n",
    "train_df['summary'] = train_df['summary'].apply(lambda x: x.strip())\n",
    "train_df['topic'] = train_df['topic'].apply(lambda x: x.strip())\n",
    "\n",
    "# 자음, 모음만으로 구성된 경우 적절한 값으로 대체\n",
    "train_df['dialogue'] = train_df['dialogue'].apply(lambda x: x.replace('제ㅏ', '제가'))\n",
    "train_df['dialogue'] = train_df['dialogue'].apply(lambda x: x.replace('척했ㄷ거든', '척했거든'))\n",
    "train_df['dialogue'] = train_df['dialogue'].apply(lambda x: x.replace('배경ㅇ로', '배경으로'))\n",
    "train_df['dialogue'] = train_df['dialogue'].apply(lambda x: x.replace('ㅋㅋ', '웃기다'))\n",
    "train_df['dialogue'] = train_df['dialogue'].apply(lambda x: x.replace('아직ㅍ알맞는', '아직 알맞는'))\n",
    "train_df['summary'] = train_df['summary'].apply(lambda x: x.replace('머라이어 ㅐ리', '머라이어 캐리'))\n",
    "\n",
    "# special_tokens는 학습할 때 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../../data/train_data-preprocessing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BartForConditionalGeneration, BartConfig\n",
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration, T5Config\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다.\n",
    "\n",
    "# visualization\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/NanumFont/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "model_dir = \"lcw99/t5-base-korean-text-summary\"\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_dir) \n",
    "\n",
    "# https://huggingface.co/paust/pko-t5-base\n",
    "# transformers 의 API 를 사용하여 접근 가능합니다. \n",
    "# tokenizer 를 사용할때는 T5Tokenizer 가 아니라 T5TokenizerFast 를 사용해주십시오. \n",
    "# model 은 T5ForConditionalGeneration 를 그대로 활용하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"your_path\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": f\"{model_dir}\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 1024,\n",
    "        \"decoder_max_len\": 150,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        \"unk_token\": f\"{tokenizer.unk_token}\",\n",
    "        \"pad_token\": f\"{tokenizer.pad_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#Person4#', '#Person5#', '#Person6#', '#Person7#',\n",
    "                           '#DateOfBirth#', '#CarNumber#', '#Email#', '#CardNumber#', '#Address#', '#SSN#', '#PhoneNumber#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 50,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 4, # 50\n",
    "        \"per_device_eval_batch_size\": 16, # 32\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 16, # 몇 개의 작은 배치를 합쳐서 큰 배치처럼 처리할지를 결정하는 파라미터: 메모리 제한 극복, 더 나은 성능\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 7,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 150,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 5, # 3\n",
    "        \"early_stopping_threshold\": 0.0001, # 0.001\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"entity_name\",\n",
    "        \"project\": \"project_name\",\n",
    "        \"name\": \"name\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 150,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 16, # 32\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.unk_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "loaded_config['general']['data_path'] = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "display(train_df.tail())\n",
    "\n",
    "# dev data의 구조와 내용을 확인합니다.\n",
    "dev_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "display(dev_df.tail())\n",
    "\n",
    "train_df_copy = train_df.copy()\n",
    "dev_df_copy = dev_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대화문에 개행문자 적용 잘 되어있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dialogue_n = train_df_copy['dialogue'].apply(lambda x: x.count('\\n'))\n",
    "train_dialogue_n.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1_list = train_dialogue_n[train_dialogue_n <= 1].reset_index()['index'].tolist()\n",
    "for idx in n_1_list:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('-----'*20)\n",
    "    print(train_df_copy.iloc[idx, 1])\n",
    "    print('-----'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# special token을 통해 적절하지 않은 형식 찾기\n",
    "\n",
    "> 데이터 전처리에서 얻은 special token\n",
    "\n",
    "{'#Person3#', '#PhoneNumber#', '#Person5#', '#PassportNumber#', '#DateOfBirth#', '#Address#', '#Person6#', '#CarNumber#', '#SSN#', '#Person7#', '#CardNumber#', '#Person4#', '#Person2#', '#Person#', '#Email#', '#Person1#'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findall_pattern(df, pattern):\n",
    "    idx_list = []\n",
    "    for idx in range(0, df.shape[0]):\n",
    "        text = df.loc[idx, 'dialogue']\n",
    "        pattern = pattern\n",
    "        masked = re.findall(pattern, text)\n",
    "        if len(masked) > 0:\n",
    "            idx_list.append(idx)\n",
    "    return idx_list, masked\n",
    "\n",
    "def fullmatch_pattern(df, pattern):\n",
    "    idx_list = []\n",
    "    for idx in range(0, df.shape[0]):\n",
    "        text = df.loc[idx, 'dialogue']\n",
    "        pattern = pattern\n",
    "        masked = re.fullmatch(pattern, text)\n",
    "        if len(masked) > 0:\n",
    "            idx_list.append(idx)\n",
    "    return idx_list, masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_person = train_df.copy()\n",
    "del_token = ['#PhoneNumber#', '#PassportNumber#', '#DateOfBirth#', '#Address#', '#CarNumber#', '#SSN#', '#CardNumber#', '#Email#']\n",
    "pattern = '|'.join(re.escape(token) for token in del_token)\n",
    "for idx in tqdm(range(0, train_df_copy.shape[0])):\n",
    "    text = train_df_copy.iloc[idx, 1]\n",
    "    text2 = re.sub(pattern, '', text)\n",
    "    train_df_person.iloc[idx, 1] = text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df_person.iloc[12428, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person이 아니라 한국어인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list, _ = findall_pattern(train_df_person, r'#[가-힣]+')\n",
    "for idx in idx_list:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(train_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list), idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어와 한국어이면서, 마지막이 숫자가 없거나 #으로 안 끝나는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list2, _ = findall_pattern(train_df_person, r'#\\b[A-Za-z가-힣]+\\b')\n",
    "for idx in idx_list2:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(train_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list2), idx_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫시작에 #이 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list3, _ = findall_pattern(train_df_person, r'(?<!#)\\b[A-Za-z가-힣0-9]+\\b#')\n",
    "for idx in idx_list3:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(train_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 양쪽에 #이 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list4, _ = findall_pattern(train_df_person, r'(?<!#)\\b사람[0-9]+:\\s\\b') # 사람 Person\n",
    "for idx in idx_list4:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(train_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4가지 경우의 인덱스 값들 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_idx = list(set(idx_list + idx_list2 + idx_list3 + idx_list4))\n",
    "person_idx = sorted(person_idx)\n",
    "print(len(person_idx), person_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in person_idx:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(train_df_copy.iloc[idx, 1])\n",
    "    print('----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    re.sub(r'#PhoneNumber[가-힣]', '#PhoneNumber#', train_df_copy.iloc[420, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.iloc[420, 1] = re.sub(r'#PhoneNumber[가-힣]', '#PhoneNumber#', train_df_copy.iloc[420, 1])\n",
    "train_df_copy.iloc[839, 1] = re.sub(r'#사람1', '#Person1#: ', train_df_copy.iloc[839, 1])\n",
    "train_df_copy.iloc[1125, 1] = re.sub(r'사람1#', '#Person1#', train_df_copy.iloc[1125, 1])\n",
    "\n",
    "train_df_copy.iloc[1142, 1] = re.sub(r'사람1#', '#Person1#', train_df_copy.iloc[1142, 1])\n",
    "train_df_copy.iloc[1213, 1] = re.sub(r'#하지만', '#Person1#:', train_df_copy.iloc[1213, 1])\n",
    "train_df_copy.iloc[1236, 1] = re.sub(r'#고객님', '#Person2#: 고객님', train_df_copy.iloc[1236, 1])\n",
    "\n",
    "train_df_copy.iloc[1250, 1] = re.sub(r'#여기', '#Person1#: 여기', train_df_copy.iloc[1250, 1])\n",
    "train_df_copy.iloc[1266, 1] = re.sub(r'#고객님', '#Person2#: 고객님', train_df_copy.iloc[1266, 1])\n",
    "train_df_copy.iloc[1278, 1] = re.sub(r'#고객님', '#Person2#: 고객님', train_df_copy.iloc[1278, 1])\n",
    "\n",
    "train_df_copy.iloc[1281, 1] = re.sub(r'#잠깐만요', '#Person1#: 잠깐만요', train_df_copy.iloc[1281, 1])\n",
    "train_df_copy.iloc[1283, 1] = re.sub(r'#어디', '#Person1#: 어디', train_df_copy.iloc[1283, 1])\n",
    "train_df_copy.iloc[1301, 1] = re.sub(r'#샐러드용', '#Person1#: 샐러드용', train_df_copy.iloc[1301, 1])\n",
    "\n",
    "train_df_copy.iloc[1302, 1] = re.sub(r'#페리에와', '#Person1#: 페리에와', train_df_copy.iloc[1302, 1])\n",
    "train_df_copy.iloc[1306, 1] = re.sub(r'#나', '#Person2#: 나', train_df_copy.iloc[1306, 1])\n",
    "train_df_copy.iloc[1322, 1] = re.sub(r'#여기서', '#Person1#: 여기서', train_df_copy.iloc[1322, 1])\n",
    "\n",
    "train_df_copy.iloc[1547, 1] = re.sub(r'#작은', '#Person2#: 작은', train_df_copy.iloc[1547, 1])\n",
    "train_df_copy.iloc[1609, 1] = re.sub(r'#여기', '#Person2#: 여기', train_df_copy.iloc[1609, 1])\n",
    "train_df_copy.iloc[1899, 1] = re.sub(r'#Person#', '#Person2#', train_df_copy.iloc[1899, 1])\n",
    "\n",
    "train_df_copy.iloc[4537, 1] = re.sub(r'#Person\\s', '#Person', train_df_copy.iloc[4537, 1])\n",
    "train_df_copy.iloc[9750, 1] = re.sub(r'(?<!#)Person', '#Person', train_df_copy.iloc[9750, 1])\n",
    "train_df_copy.iloc[9779, 1] = re.sub(r'(?<!#)Person', '#Person', train_df_copy.iloc[9779, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_person.iloc[420, 1] = re.sub(r'#PhoneNumber[가-힣]', '#PhoneNumber#', train_df_person.iloc[420, 1])\n",
    "train_df_person.iloc[839, 1] = re.sub(r'#사람1', '#Person1#: ', train_df_person.iloc[839, 1])\n",
    "train_df_person.iloc[1125, 1] = re.sub(r'사람1#', '#Person1#', train_df_person.iloc[1125, 1])\n",
    "\n",
    "train_df_person.iloc[1142, 1] = re.sub(r'사람1#', '#Person1#', train_df_person.iloc[1142, 1])\n",
    "train_df_person.iloc[1213, 1] = re.sub(r'#하지만', '#Person1#:', train_df_person.iloc[1213, 1])\n",
    "train_df_person.iloc[1236, 1] = re.sub(r'#고객님', '#Person2#: 고객님', train_df_person.iloc[1236, 1])\n",
    "\n",
    "train_df_person.iloc[1250, 1] = re.sub(r'#여기', '#Person1#: 여기', train_df_person.iloc[1250, 1])\n",
    "train_df_person.iloc[1266, 1] = re.sub(r'#고객님', '#Person2#: 고객님', train_df_person.iloc[1266, 1])\n",
    "train_df_person.iloc[1278, 1] = re.sub(r'#고객님', '#Person2#: 고객님', train_df_person.iloc[1278, 1])\n",
    "\n",
    "train_df_person.iloc[1281, 1] = re.sub(r'#잠깐만요', '#Person1#: 잠깐만요', train_df_person.iloc[1281, 1])\n",
    "train_df_person.iloc[1283, 1] = re.sub(r'#어디', '#Person1#: 어디', train_df_person.iloc[1283, 1])\n",
    "train_df_person.iloc[1301, 1] = re.sub(r'#샐러드용', '#Person1#: 샐러드용', train_df_person.iloc[1301, 1])\n",
    "\n",
    "train_df_person.iloc[1302, 1] = re.sub(r'#페리에와', '#Person1#: 페리에와', train_df_person.iloc[1302, 1])\n",
    "train_df_person.iloc[1306, 1] = re.sub(r'#나', '#Person2#: 나', train_df_person.iloc[1306, 1])\n",
    "train_df_person.iloc[1322, 1] = re.sub(r'#여기서', '#Person1#: 여기서', train_df_person.iloc[1322, 1])\n",
    "\n",
    "train_df_person.iloc[1547, 1] = re.sub(r'#작은', '#Person2#: 작은', train_df_person.iloc[1547, 1])\n",
    "train_df_person.iloc[1609, 1] = re.sub(r'#여기', '#Person2#: 여기', train_df_person.iloc[1609, 1])\n",
    "train_df_person.iloc[1899, 1] = re.sub(r'#Person#', '#Person2#', train_df_person.iloc[1899, 1])\n",
    "\n",
    "train_df_person.iloc[4537, 1] = re.sub(r'#Person\\s', '#Person', train_df_person.iloc[4537, 1])\n",
    "train_df_person.iloc[9750, 1] = re.sub(r'(?<!#)Person', '#Person', train_df_person.iloc[9750, 1])\n",
    "train_df_person.iloc[9779, 1] = re.sub(r'(?<!#)Person', '#Person', train_df_person.iloc[9779, 1])\n",
    "\n",
    "idx_list, _ = findall_pattern(train_df_person, r'#[가-힣]+')\n",
    "idx_list2, _ = findall_pattern(train_df_person, r'#\\b[A-Za-z가-힣]+\\b')\n",
    "idx_list3, _ = findall_pattern(train_df_person, r'(?<!#)\\b[A-Za-z가-힣0-9]+\\b#')\n",
    "idx_list4, _ = findall_pattern(train_df_person, r'(?<!#)\\b사람[0-9]+:\\s\\b') # 사람 Person\n",
    "\n",
    "person_idx = list(set(idx_list + idx_list2 + idx_list3 + idx_list4))\n",
    "person_idx = sorted(person_idx)\n",
    "print(len(person_idx), person_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 화자가 연속되는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_masking(pattern, text):\n",
    "    masked = re.findall(pattern, text)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = train_df_copy['dialogue'].apply(lambda x: str(reg_masking(r'#\\bPerson[0-9]+\\b#', x)))\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    print(masked_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_person(word_list):\n",
    "    for i in range(len(word_list) - 1):\n",
    "        if word_list[i] == word_list[i+1]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = masked_train.reset_index()\n",
    "train_df_repeat = masked_train['dialogue'].apply(lambda x: x.lstrip('[').rstrip(']').replace(\"', '\", ' ').strip(\"'\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_repeat = []\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    if repeat_person(train_df_repeat[idx]) == True:\n",
    "        idx_repeat.append(idx)\n",
    "print(len(idx_repeat), idx_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_repeat:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('-----'*20)\n",
    "    print(train_df_copy.iloc[idx, 1])\n",
    "    # print(f'>>> {train_df_copy.iloc[idx, 2]}')\n",
    "    print('-----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = re.sub(r'않았어요.\\r\\n#Person1#: ', r'않았어요. ', train_df_copy.iloc[11578, 1])\n",
    "# temp = re.sub(r'\\n#Person1#: 컴퓨터', ' 컴퓨터', temp)\n",
    "# temp = re.sub(r'#Person2#: 그래', '#Person1#: 그래', temp)\n",
    "# temp = re.sub(r'#Person1#: 지금', '#Person2#: 지금', temp)\n",
    "# temp = re.sub(r'#Person2#: 좋아', '#Person1#: 좋아', temp)\n",
    "\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.iloc[345, 1] = re.sub(r'#Person1#: 아니요.', '#Person2#: 아니요.', train_df_copy.iloc[345, 1])\n",
    "train_df_copy.iloc[484, 1] = re.sub(r'인상적이네.\\s', '인상적이네. \\n#Person2#: ', train_df_copy.iloc[484, 1])\n",
    "train_df_copy.iloc[756, 1] = re.sub(r'#Person1#: 오, 안녕, 피비!\\n#Person2#:\\s', '#Person2#: 오, 안녕, 피비! ', train_df_copy.iloc[756, 1])\n",
    "\n",
    "train_df_copy.iloc[872, 1] = re.sub(r'#Person1#: 중국은행', '#Person2#: 중국은행', train_df_copy.iloc[872, 1])\n",
    "\n",
    "temp = re.sub(r'#Person1#: 적자생존', '#Person2#: 적자생존', train_df_copy.iloc[925, 1])\n",
    "train_df_copy.iloc[925, 1] = re.sub(r'#Person2#: 맞아요', r'#Person1#: 맞아요', temp)\n",
    "\n",
    "train_df_copy.iloc[982, 1] = re.sub(r'일이죠\\?\\n#Person2#:\\s', '일이죠? ', train_df_copy.iloc[982, 1])\n",
    "\n",
    "temp = re.sub(r'#Person2#: 아마도', '#Person1#: 아마도', train_df_copy.iloc[1033, 1])\n",
    "temp = re.sub(r'#Person1#:\\s\\s', '#Person2#: ', temp)\n",
    "temp = re.sub(r'#Person2#: 그래', '#Person1#: 그래', temp)\n",
    "temp = re.sub(r'#Person1#: 지금', '#Person2#: 지금', temp)\n",
    "train_df_copy.iloc[1033, 1] = re.sub(r'#Person2#: 좋아', '#Person1#: 좋아', temp)\n",
    "\n",
    "train_df_copy.iloc[1220, 1] = re.sub(r'#Person2#: 음', '#Person1#: 음', train_df_copy.iloc[1220, 1])\n",
    "train_df_copy.iloc[1294, 1] = re.sub(r'#Person1#: 네,', '#Person2#: 네,', train_df_copy.iloc[1294, 1])\n",
    "\n",
    "train_df_copy.iloc[1419, 1] = re.sub(r'\\n#Person1#: 어떠세요\\?', ' 어떠세요?', train_df_copy.iloc[1419, 1])\n",
    "train_df_copy.iloc[1424, 1] = re.sub(r'\\s방으로', '#Person1#: 방으로', train_df_copy.iloc[1424, 1])\n",
    "train_df_copy.iloc[1440, 1] = re.sub(r'\\s언제 예약하시겠습니까\\?', '\\n#Person1#: 언제 예약하시겠습니까?', train_df_copy.iloc[1440, 1])\n",
    "\n",
    "temp = re.sub(r'#Person2#: 그거', '#Person1#: 그거', train_df_copy.iloc[1475, 1])\n",
    "train_df_copy.iloc[1475, 1] = re.sub(r'\\n#Person1#: 컴퓨터', ' 컴퓨터', temp)\n",
    "\n",
    "train_df_copy.iloc[1497, 1] = re.sub(r'\\n\\s복사', '\\n#Person1#: 복사', train_df_copy.iloc[1497, 1])\n",
    "train_df_copy.iloc[1791, 1] = re.sub(r'#Person1#: 봐', '#Person2#: 봐', train_df_copy.iloc[1791, 1])\n",
    "\n",
    "train_df_copy.iloc[3628, 1] = re.sub(r'아니라고요. 당신의', '아니라고요.\\n#Person1#: 당신의', train_df_copy.iloc[3628, 1])\n",
    "\n",
    "repl_text = '#Person1#: 안녕, 내가 왔어! 음. . . 너의 머리가 꽤 손상되었고, 끝이 갈라져있어.\\n#Person2#: 정말? 어떻게 해야 할까?\\n#Person1#: 잘라내면 갈라진 끝은 해결될 거야, 하지만 딥 컨디셔닝 트리트먼트가 필요할 수도 있어.\\n#Person2#: 음, 알겠어. 네가 도움이 될 것 같다고 생각하는 대로 해줘.\\n#Person1#: 얼굴을 감싸는 레이어도 추가할 거야.\\n#Person2#: 위쪽으로 가위로 손을 좀 봐줄 수 있을까? 내 머리 숫이 정말 많아.\\n#Person1#: 문제 없어!'\n",
    "train_df_copy.iloc[5441, 1] = repl_text\n",
    "\n",
    "train_df_copy.iloc[6759, 1] = re.sub(r'\\n#Person2#: 아', '아', train_df_copy.iloc[6759, 1])\n",
    "\n",
    "train_df_copy.iloc[6799, 1] = re.sub(r'#Person1#: 그,', '#Person2#: 그,', train_df_copy.iloc[6799, 1])\n",
    "train_df_copy.iloc[8645, 1] = re.sub(r'#Person2#: 저는 서프라이즈', '#Person1#: 저는 서프라이즈', train_df_copy.iloc[8645, 1])\n",
    "train_df_copy.iloc[9898, 1] = re.sub(r'#Person1#: 오', '#Person2#: 오', train_df_copy.iloc[9898, 1])\n",
    "\n",
    "train_df_copy.iloc[11578, 1] = re.sub(r'않았어요.\\r\\n#Person1#: ', r'않았어요. ', train_df_copy.iloc[11578, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = train_df_copy['dialogue'].apply(lambda x: str(reg_masking(r'#\\bPerson[0-9]+\\b#', x)))\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    print(masked_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = masked_train.reset_index()\n",
    "train_df_repeat = masked_train['dialogue'].apply(lambda x: x.lstrip('[').rstrip(']').replace(\"', '\", ' ').strip(\"'\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_repeat = []\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    if repeat_person(train_df_repeat[idx]) == True:\n",
    "        idx_repeat.append(idx)\n",
    "print(len(idx_repeat), idx_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_person = dev_df.copy()\n",
    "del_token = ['#PhoneNumber#', '#PassportNumber#', '#DateOfBirth#', '#Address#', '#CarNumber#', '#SSN#', '#CardNumber#', '#Email#']\n",
    "pattern = '|'.join(re.escape(token) for token in del_token)\n",
    "for idx in tqdm(range(0, dev_df_copy.shape[0])):\n",
    "    text = dev_df_copy.iloc[idx, 1]\n",
    "    text2 = re.sub(pattern, '', text)\n",
    "    dev_df_person.iloc[idx, 1] = text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person이 아니라 한국어인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list, _ = findall_pattern(dev_df_person, r'#[가-힣]+')\n",
    "for idx in idx_list:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(dev_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list), idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어와 한국어이면서, 마지막이 숫자가 없거나 #으로 안 끝나는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list2, _ = findall_pattern(dev_df_person, r'#\\b[A-Za-z가-힣]+\\b')\n",
    "for idx in idx_list2:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(dev_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list2), idx_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫시작에 #이 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list3, _ = findall_pattern(dev_df_person, r'(?<!#)\\b[A-Za-z가-힣0-9]+\\b#')\n",
    "for idx in idx_list3:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(dev_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 양쪽에 #이 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list4, _ = findall_pattern(dev_df_person, r'(?<!#)\\b사람[0-9]+:\\s\\b') # 사람 Person\n",
    "for idx in idx_list4:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(dev_df_person.iloc[idx, 1])\n",
    "    print('----'*20)\n",
    "print(len(idx_list4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4가지 경우의 인덱스 값들 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_idx = list(set(idx_list + idx_list2 + idx_list3 + idx_list4))\n",
    "person_idx = sorted(person_idx)\n",
    "print(len(person_idx), person_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in person_idx:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('----'*20)\n",
    "    print(dev_df_copy.iloc[idx, 1])\n",
    "    print('----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    re.sub(r'#B형', '#Person1#: B형', dev_df_copy.iloc[63, 1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_copy.iloc[48, 1] = re.sub(r'#다음', '#Person1#: 다음', dev_df_copy.iloc[48, 1])\n",
    "dev_df_copy.iloc[63, 1] = re.sub(r'#B형', '#Person1#: B형', dev_df_copy.iloc[63, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_person.iloc[48, 1] = re.sub(r'#다음', '#Person1#: 다음', dev_df_person.iloc[48, 1])\n",
    "dev_df_person.iloc[63, 1] = re.sub(r'#B형', '#Person1#: B형', dev_df_person.iloc[63, 1])\n",
    "\n",
    "idx_list, _ = findall_pattern(dev_df_person, r'#[가-힣]+')\n",
    "idx_list2, _ = findall_pattern(dev_df_person, r'#\\b[A-Za-z가-힣]+\\b')\n",
    "idx_list3, _ = findall_pattern(dev_df_person, r'(?<!#)\\b[A-Za-z가-힣0-9]+\\b#')\n",
    "idx_list4, _ = findall_pattern(dev_df_person, r'(?<!#)\\b사람[0-9]+:\\s\\b') # 사람 Person\n",
    "\n",
    "person_idx = list(set(idx_list + idx_list2 + idx_list3 + idx_list4))\n",
    "person_idx = sorted(person_idx)\n",
    "print(len(person_idx), person_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 화자가 연속되는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_masking(pattern, text):\n",
    "    masked = re.findall(pattern, text)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = dev_df_copy['dialogue'].apply(lambda x: str(reg_masking(r'#\\bPerson[0-9]+\\b#', x)))\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    print(masked_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_person(word_list):\n",
    "    for i in range(len(word_list) - 1):\n",
    "        if word_list[i] == word_list[i+1]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = masked_train.reset_index()\n",
    "dev_df_repeat = masked_train['dialogue'].apply(lambda x: x.lstrip('[').rstrip(']').replace(\"', '\", ' ').strip(\"'\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_repeat = []\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    if repeat_person(dev_df_repeat[idx]) == True:\n",
    "        idx_repeat.append(idx)\n",
    "print(len(idx_repeat), idx_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in idx_repeat:\n",
    "    print(f'\\n[{idx}]')\n",
    "    print('-----'*20)\n",
    "    print(dev_df_copy.iloc[idx, 1])\n",
    "    # print(f'>>> {train_df_copy.iloc[idx, 2]}')\n",
    "    print('-----'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = re.sub(r'#Person2#: 뭐', r'#Person1#: 뭐', dev_df_copy.iloc[437, 1])\n",
    "temp = re.sub(r'#Person1#: 봐', r'#Person2#: 봐', temp)\n",
    "temp = re.sub(r'#Person2#: 그래', r'#Person1#: 그래', temp)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = re.sub(r'#Person2#: 뭐', r'#Person1#: 뭐', dev_df_copy.iloc[437, 1])\n",
    "temp = re.sub(r'#Person1#: 봐', r'#Person2#: 봐', temp)\n",
    "dev_df_copy.iloc[437, 1] = re.sub(r'#Person2#: 그래', r'#Person1#: 그래', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = dev_df_copy['dialogue'].apply(lambda x: str(reg_masking(r'#\\bPerson[0-9]+\\b#', x)))\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    print(masked_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_train = masked_train.reset_index()\n",
    "dev_df_repeat = masked_train['dialogue'].apply(lambda x: x.lstrip('[').rstrip(']').replace(\"', '\", ' ').strip(\"'\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_repeat = []\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    if repeat_person(dev_df_repeat[idx]) == True:\n",
    "        idx_repeat.append(idx)\n",
    "print(len(idx_repeat), idx_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# special token 재확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_masking(text):\n",
    "    pattern = r'#\\w+#'\n",
    "    masked = re.findall(pattern, text)\n",
    "    return masked\n",
    "\n",
    "masked = train_df_copy['dialogue'].apply(lambda x: str(set(reg_masking(x)))) # dev_df_copy\n",
    "for idx in range(0, train_df_copy.shape[0]): # dev_df_copy\n",
    "    print(masked[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = masked.reset_index()\n",
    "temp_df['dialogue'] = temp_df['dialogue'].apply(lambda x: set(eval(x)))\n",
    "unique_dialogues = set().union(*temp_df['dialogue'])\n",
    "print(sorted(unique_dialogues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좌우 공백 제거\n",
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: x.strip())\n",
    "train_df_copy['summary'] = train_df_copy['summary'].apply(lambda x: x.strip())\n",
    "train_df_copy['topic'] = train_df_copy['topic'].apply(lambda x: x.strip())\n",
    "\n",
    "# 자음, 모음만으로 구성된 경우 적절한 값으로 대체\n",
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: x.replace('제ㅏ', '제가'))\n",
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: x.replace('척했ㄷ거든', '척했거든'))\n",
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: x.replace('배경ㅇ로', '배경으로'))\n",
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: x.replace('ㅋㅋ', '웃기다'))\n",
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: x.replace('아직ㅍ알맞는', '아직 알맞는'))\n",
    "train_df_copy['summary'] = train_df_copy['summary'].apply(lambda x: x.replace('머라이어 ㅐ리', '머라이어 캐리'))\n",
    "\n",
    "# 좌우 공백 제거\n",
    "dev_df_copy['dialogue'] = dev_df_copy['dialogue'].apply(lambda x: x.strip())\n",
    "dev_df_copy['summary'] = dev_df_copy['summary'].apply(lambda x: x.strip())\n",
    "dev_df_copy['topic'] = dev_df_copy['topic'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.to_csv('../../data/train_regular-expression.csv', index=False)\n",
    "dev_df_copy.to_csv('../../data/dev_regular-expression.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대화 중 괄호 안에 있는 문장 제거 / 기타 기호\n",
    "\n",
    "> token-check 반영한 데이터셋 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_path,'train_token-check.csv'))\n",
    "dev_df = pd.read_csv(os.path.join(data_path,'dev_token-check.csv'))\n",
    "train_df_copy = train_df.copy()\n",
    "dev_df_copy = dev_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 괄호 안에 있는 문장 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[네.]]]<<>(네!)[네?]<ab?>'\n",
    "pattern = r'\\[[^\\[\\]]+\\]|\\([^\\(\\)]+\\)|\\<[^\\<\\>]+\\>'\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    text = train_df_copy.iloc[idx, 1]\n",
    "    temp = re.findall(pattern, text)\n",
    "    if len(temp) > 0:\n",
    "        temp_list.append(idx)\n",
    "print(len(temp_list), temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df_copy.iloc[temp_list]\n",
    "for i in range(0, temp_df.shape[0]):\n",
    "    dia = temp_df.iloc[i, 1]\n",
    "    sum = temp_df.iloc[i, 2]\n",
    "    print('-----'*20)\n",
    "    print('[대화]')\n",
    "    print(dia)\n",
    "    print('[요약]')\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: re.sub(pattern, '', x))\n",
    "print(temp_df.iloc[0, 1])\n",
    "print('-----'*20)\n",
    "print(train_df_copy.iloc[26, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '네, 네. 네? 네! 네~ \"네\"' # '\n",
    "pattern = r'[,~\"]'\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    text = train_df_copy.iloc[idx, 1]\n",
    "    temp = re.findall(pattern, text)\n",
    "    if len(temp) > 0:\n",
    "        temp_list.append(idx)\n",
    "print(len(temp_list), temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df_copy.iloc[temp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: re.sub(pattern, '', x))\n",
    "print(temp_df.iloc[0, 1])\n",
    "print('-----'*20)\n",
    "print(train_df_copy.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"'네'\"\n",
    "pattern = r\"\\'\"\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for idx in range(0, train_df_copy.shape[0]):\n",
    "    text = train_df_copy.iloc[idx, 1]\n",
    "    temp = re.findall(pattern, text)\n",
    "    if len(temp) > 0:\n",
    "        temp_list.append(idx)\n",
    "print(len(temp_list), temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = train_df_copy.iloc[temp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy['dialogue'] = train_df_copy['dialogue'].apply(lambda x: re.sub(pattern, '', x))\n",
    "print(temp_df.iloc[0, 1])\n",
    "print('-----'*20)\n",
    "print(train_df_copy.iloc[33, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 괄호 안에 있는 문장 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[네.]]]<<>(네!)[네?]<ab?>'\n",
    "pattern = r'\\[[^\\[\\]]+\\]|\\([^\\(\\)]+\\)|\\<[^\\<\\>]+\\>'\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    text = dev_df_copy.iloc[idx, 1]\n",
    "    temp = re.findall(pattern, text)\n",
    "    if len(temp) > 0:\n",
    "        temp_list.append(idx)\n",
    "print(len(temp_list), temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = dev_df_copy.iloc[temp_list]\n",
    "for i in range(0, temp_df.shape[0]):\n",
    "    dia = temp_df.iloc[i, 1]\n",
    "    sum = temp_df.iloc[i, 2]\n",
    "    print('-----'*20)\n",
    "    print('[대화]')\n",
    "    print(dia)\n",
    "    print('[요약]')\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_copy['dialogue'] = dev_df_copy['dialogue'].apply(lambda x: re.sub(pattern, '', x))\n",
    "print(temp_df.iloc[0, 1])\n",
    "print('-----'*20)\n",
    "print(dev_df_copy.iloc[38, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 기호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '네, 네. 네? 네! 네~ \"네\"'\n",
    "pattern = r'[,~\"]'\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    text = dev_df_copy.iloc[idx, 1]\n",
    "    temp = re.findall(pattern, text)\n",
    "    if len(temp) > 0:\n",
    "        temp_list.append(idx)\n",
    "print(len(temp_list), temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = dev_df_copy.iloc[temp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_copy['dialogue'] = dev_df_copy['dialogue'].apply(lambda x: re.sub(pattern, '', x))\n",
    "print(temp_df.iloc[0, 1])\n",
    "print('-----'*20)\n",
    "print(dev_df_copy.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"'네'\"\n",
    "pattern = r\"\\'\"\n",
    "re.findall(pattern, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "for idx in range(0, dev_df_copy.shape[0]):\n",
    "    text = dev_df_copy.iloc[idx, 1]\n",
    "    temp = re.findall(pattern, text)\n",
    "    if len(temp) > 0:\n",
    "        temp_list.append(idx)\n",
    "print(len(temp_list), temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = dev_df_copy.iloc[temp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_copy['dialogue'] = dev_df_copy['dialogue'].apply(lambda x: re.sub(pattern, '', x))\n",
    "print(temp_df.iloc[0, 1])\n",
    "print('-----'*20)\n",
    "print(dev_df_copy.iloc[54, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 알겠습니다, 감사합니다, 네 같은거도 지우려고 했으나 화자의 문장 전체가 사라지는 경우가 있어 적용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_copy.to_csv('../../data/train_regular-expression2.csv', index=False)\n",
    "dev_df_copy.to_csv('../../data/dev_regular-expression2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

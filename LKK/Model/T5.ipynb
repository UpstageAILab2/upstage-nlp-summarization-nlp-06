{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! pip install -q sentencepiece\n",
    "# !pip install -U -q transformers\n",
    "# !pip install -q accelerate==0.27.2\n",
    "# !pip install -q bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig, AutoModelForCausalLM, T5ForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback, T5Config, T5TokenizerFast, BitsAndBytesConfig\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5TokenizerFast.from_pretrained(\"paust/pko-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5TokenizerFast.from_pretrained(\"lcw99/t5-base-korean-text-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': '../data/',\n",
      "             'model_name': 'paust/pko-t5-base',\n",
      "             'output_dir': './'},\n",
      " 'inference': {'batch_size': 8,\n",
      "               'ckt_path': '../model_path/',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 100,\n",
      "               'encoder_max_len': 512,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#Email#',\n",
      "                                  '#SSN#',\n",
      "                                  'Person4',\n",
      "                                  'Person5',\n",
      "                                  'Person6',\n",
      "                                  'Person7']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 100,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 100,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 8,\n",
      "              'per_device_train_batch_size': 12,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 3,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'nlp_06',\n",
      "           'name': 'lkk_EXP14',\n",
      "           'project': 'model_selection'}}\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = \"paust/pko-t5-base\" #\"digit82/kobart-summarization\" #'gogamza/kobart-summarization' 'ainize/kobart-news' 'EbanLee/kobart-summary-v3' 'alaggung/bart-r3f'\n",
    "exp_name = 'lkk_EXP14'\n",
    "\n",
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = T5TokenizerFast.from_pretrained(pretrained_model_name)\n",
    "tokenizer.bos_token = '<s>'\n",
    "\n",
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"../data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        # \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"model_name\": pretrained_model_name, # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512, #512\n",
    "        \"decoder_max_len\": 100, #100\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#',\n",
    "                           '#CarNumber#', '#CardNumber#', '#DateOfBirth#', '#Email#', '#SSN#',\n",
    "                           'Person4', 'Person5', 'Person6', 'Person7'] #추가\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 100,\n",
    "        \"learning_rate\": 1e-5, #1e-5\n",
    "        \"per_device_train_batch_size\": 12, #50\n",
    "        \"per_device_eval_batch_size\": 8, #32\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine', #cosine\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 3,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100, #100\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3, #3\n",
    "        \"early_stopping_threshold\": 0.001, #0.001\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"nlp_06\",\n",
    "        \"project\": \"model_selection\",\n",
    "        \"name\": exp_name\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"../model_path/\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100, #100\n",
    "        \"num_beams\": 4, #4\n",
    "        \"batch_size\" : 8, #32\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)\n",
    "\n",
    "# 실험에 쓰일 데이터의 경로, 사용될 모델, 모델의 최종 출력 결과를 저장할 경로에 대해 확인합니다.\n",
    "loaded_config['general']\n",
    "\n",
    "# 이곳에 사용자가 저장한 데이터 dir 설정하기\n",
    "# loaded_config['general']['data_path'] = \"data_path\"\n",
    "\n",
    "# 데이터 전처리를 하기 위해 tokenization 과정에서 필요한 정보들을 확인합니다.\n",
    "loaded_config['tokenizer']\n",
    "\n",
    "# 모델이 훈련 시 적용될 매개변수를 확인합니다.\n",
    "loaded_config['training']\n",
    "\n",
    "# 모델 학습 과정에 대한 정보를 제공해주는 wandb 설정 내용을 확인합니다.\n",
    "loaded_config['wandb']\n",
    "\n",
    "# (선택) 이곳에 사용자가 사용할 wandb config 설정\n",
    "loaded_config['wandb']['entity'] = \"nlp_06\"\n",
    "loaded_config['wandb']['project'] = \"model_selection\"\n",
    "loaded_config['wandb']['name'] = exp_name\n",
    "\n",
    "# 모델이 최종 결과를 출력하기 위한 매개변수 정보를 확인합니다.\n",
    "loaded_config['inference']\n",
    "\n",
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "\n",
    "# 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # 실험에 필요한 컬럼을 가져옵니다.\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    # BART 모델의 입력, 출력 형태를 맞추기 위해 전처리를 진행합니다.\n",
    "    def make_input(self, dataset,is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truth를 디코더의 input으로 사용하여 학습합니다.\n",
    "            decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n",
    "\n",
    "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        # item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        # item2['decoder_input_ids'] = item2['input_ids']\n",
    "        # item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        # item2.pop('input_ids')\n",
    "        # item2.pop('attention_mask')\n",
    "        # item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        # item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        # item2['decoder_input_ids'] = item2['input_ids']\n",
    "        # item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        # item2.pop('input_ids')\n",
    "        # item2.pop('attention_mask')\n",
    "        # item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Test에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset\n",
    "\n",
    "# 모델 성능에 대한 평가 지표를 정의합니다. 본 대회에서는 ROUGE 점수를 통해 모델의 성능을 평가합니다.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거합니다.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # 최종적인 ROUGE 점수를 계산합니다.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE 점수 중 F-1 score를 통해 평가합니다.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result\n",
    "\n",
    "# 학습을 위한 trainer 클래스와 매개변수를 정의합니다.\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    print('-'*10, 'Make training arguments', '-'*10,)\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'], # model output directory\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
    "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'], # 최종적으로 가장 높은 점수 저장\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to'] # (선택) wandb를 사용할 때 설정합니다.\n",
    "            )\n",
    "\n",
    "    # (선택) 모델의 학습 과정을 추적하는 wandb를 사용하기 위해 초기화 해줍니다.\n",
    "    wandb.init(\n",
    "        entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "    )\n",
    "\n",
    "    # (선택) 모델 checkpoint를 wandb에 저장하도록 환경 변수를 설정합니다.\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # Validation loss가 더 이상 개선되지 않을 때 학습을 중단시키는 EarlyStopping 기능을 사용합니다.\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer 클래스를 정의합니다.\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model, # 사용자가 사전 학습하기 위해 사용할 모델을 입력합니다.\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : paust/pko-t5-base ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"_name_or_path\": \"paust/pko-t5-base\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.41.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50373\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- tokenizer special tokens :  {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<pad>', 'pad_token': '<pad>', 'additional_special_tokens': ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#', '#CarNumber#', '#CardNumber#', '#DateOfBirth#', '#Email#', '#SSN#', 'Person4', 'Person5', 'Person6', 'Person7']} ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "train_label:\n",
      " 스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n",
      "#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n",
      "#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n",
      "#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n",
      "#Person1#: 알고 있는 알레르기가 있나요?\n",
      "#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n",
      "#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n",
      "#Person2#: 운동을 할 때 많이 나타나요.\n",
      "#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n",
      "#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n",
      "val_label:\n",
      " #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.\n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "---------- Make training arguments ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdydekqch3217\u001b[0m (\u001b[33mnlp_06\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/code/wandb/run-20240523_033330-k15flmyc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp_06/model_selection/runs/k15flmyc' target=\"_blank\">lkk_EXP14</a></strong> to <a href='https://wandb.ai/nlp_06/model_selection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp_06/model_selection' target=\"_blank\">https://wandb.ai/nlp_06/model_selection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp_06/model_selection/runs/k15flmyc' target=\"_blank\">https://wandb.ai/nlp_06/model_selection/runs/k15flmyc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20760' max='103800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 20760/103800 2:25:25 < 9:41:44, 2.38 it/s, Epoch 20/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.143200</td>\n",
       "      <td>10.250263</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.083725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.973700</td>\n",
       "      <td>1.172895</td>\n",
       "      <td>0.184561</td>\n",
       "      <td>0.034187</td>\n",
       "      <td>0.182893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.066700</td>\n",
       "      <td>0.802673</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.046712</td>\n",
       "      <td>0.202827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.864700</td>\n",
       "      <td>0.737620</td>\n",
       "      <td>0.227674</td>\n",
       "      <td>0.058959</td>\n",
       "      <td>0.223156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.792900</td>\n",
       "      <td>0.643372</td>\n",
       "      <td>0.252400</td>\n",
       "      <td>0.064502</td>\n",
       "      <td>0.246699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.554816</td>\n",
       "      <td>0.273286</td>\n",
       "      <td>0.066701</td>\n",
       "      <td>0.267113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.625300</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>0.294329</td>\n",
       "      <td>0.070092</td>\n",
       "      <td>0.287540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.510820</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>0.073014</td>\n",
       "      <td>0.287810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.568800</td>\n",
       "      <td>0.502751</td>\n",
       "      <td>0.303721</td>\n",
       "      <td>0.077946</td>\n",
       "      <td>0.295936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>0.491750</td>\n",
       "      <td>0.310617</td>\n",
       "      <td>0.084995</td>\n",
       "      <td>0.302454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.530300</td>\n",
       "      <td>0.485925</td>\n",
       "      <td>0.313980</td>\n",
       "      <td>0.086302</td>\n",
       "      <td>0.305778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.483398</td>\n",
       "      <td>0.313503</td>\n",
       "      <td>0.087570</td>\n",
       "      <td>0.305158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.477601</td>\n",
       "      <td>0.313602</td>\n",
       "      <td>0.088202</td>\n",
       "      <td>0.304211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.488300</td>\n",
       "      <td>0.475013</td>\n",
       "      <td>0.318363</td>\n",
       "      <td>0.092015</td>\n",
       "      <td>0.308718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.474426</td>\n",
       "      <td>0.318160</td>\n",
       "      <td>0.093456</td>\n",
       "      <td>0.309144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.464900</td>\n",
       "      <td>0.472133</td>\n",
       "      <td>0.320646</td>\n",
       "      <td>0.091915</td>\n",
       "      <td>0.310982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.454700</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>0.324740</td>\n",
       "      <td>0.094092</td>\n",
       "      <td>0.315122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.469893</td>\n",
       "      <td>0.327571</td>\n",
       "      <td>0.099789</td>\n",
       "      <td>0.318684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.471615</td>\n",
       "      <td>0.323581</td>\n",
       "      <td>0.098726</td>\n",
       "      <td>0.315090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.425700</td>\n",
       "      <td>0.469565</td>\n",
       "      <td>0.318882</td>\n",
       "      <td>0.094655</td>\n",
       "      <td>0.308508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  <extra_id_0> 오늘 하루 어땠나요? 그리고 앞으로는 어떤 증상이 나타날지 그 예방법에 대해 어떻게 알아보길 원해야 할 필요 없는지 그리고 검사를 받게 할 거예요.<extra_id_1>                                         \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  <extra_id_0> 오늘은 운동을 좀 하자. 근육을 좀 하자. 팔과 배를 운동하자. 팔과 팔목을 운동하자. 팔과 팔목을 운동하자. 팔과 팔목을 운동하자. 팔과 팔목을 운동하자.                             \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  <extra_id_0> 건강에 해로운 음식을 먹는 것을 멈춰야 해.\n",
      "병원: 왜 그런 음식을 먹는 거야?\n",
      "병원: 그래서<extra_id_1>건강에 해로운 음식을 먹는 것을 멈춰야 해.\n",
      "병원:                                     \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  산은 천식에 대한 검사를 받게 하고, 의사 선생님에게 검사를 받게 할 것이다. 의사 선생님은 천식에 대한 검사를 받게 할 것이다.                                              \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  사도는 지미와 지미를 위해 헬스장에서 농구를 하고 있다. 지미는 오늘 밤에 팔과 배를 운동한다.                                                           \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  산은 과일과 채소를 먹고 닭고기를 먹는 것을 멈추어야 한다. 닭고기는 과일과 채소를 먹는 것이 건강에 좋은 음식이라고 생각한다.                                                  \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  의사 선생님은 천식에 대한 검사를 받게 할 것이다. 의사 선생님은 천식에 대한 검사를 받게 할 것이다.                                                        \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 헤이에게 3시 30분에 헬스장에 가자고 제안한다. 헤이와 지미는 운동을 하기로 결정한다.                                                             \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  \n",
      "<extra_id_0>는 건강에 해로운 음식을 먹는 것을 멈추어야 한다. 그는 과일과 채소, 그리고 닭고기를 먹고 있다. 그는 건강에 해로운 음식을 먹는 것을 멈추기 위해 다른 음식을 먹지 않는다. 그는 닭고기를 구워서 먹으면 더 건강에 좋다고 말한다. 그는 닭고기를 \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  통증이 있는 것 같아요. 그들은 호흡을 할 때 가슴이 무겁게 느껴지며, 천식에 대한 검사를 받게 될 것입니다.                                                      \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 오늘 운동하러 가기로 결정했다. 지미는 3시 30분에 헬스장에서 만나기로 했다.                                                                 \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  진저는 건강에 해로운 음식을 먹는 것을 멈추라고 말한다. 진저는 과일과 채소, 그리고 닭고기를 먹는다.                                                             \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 말한다. 그들은 천식에 대한 검사를 받게 될 것이다.                                                             \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 오늘 운동하러 가기로 결정했다. 지미는 3시 30분에 헬스장에서 만나기로 했다.                                                                 \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 멈추어야 한다고 말한다. 그들은 과일, 채소, 그리고 닭고기를 먹는다. 그들은 과일과 채소, 그리고 닭고기를 먹는다.                                          \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person1#에게 말한다. #Person1#은 그를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 헬스장에서 농구를 하고 다리가 아프다. 지미는 헬스장에서 다리를 할 수 있다.                                                                 \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 멈추어야 한다고 말한다. #Person1#은 과일, 채소, 그리고 닭고기를 먹는다.                                                           \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person1#에게 말한다. #Person2#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 오늘 운동하러 갈 예정이다. #Person2#는 지미에게 3시 30분에 헬스장에서 만나자고 제안한다.                                                               \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 멈추어야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는다.                                                          \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 만나자고 제안한다. #Person1#은 그것을 거절한다.                                                                   \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 멈추어야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는다.                                                          \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에 가서 다리와 팔목을 운동하자고 제안한다. #Person1#은 동의한다.                                                             \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 멈추어야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 것을 제안한다.                                                    \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 #Person2#를 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 만나자고 제안한다. #Person1#은 그에게 금요일에 다리를 할 수 있다고 말한다.                                                        \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는다.                                                          \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에 가서 다리와 팔목을 운동하자고 제안한다. #Person1#은 동의한다.                                                             \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 것을 제안한다.                                                    \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에 가서 다리와 팔목을 운동하자고 제안한다. #Person1#은 그것이 너무 힘들다고 생각한다. 지미는 동의한다.                                               \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 #Person1#에게 과일, 채소, 그리고 닭고기를 먹는 것을 권장한다.                                                 \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 다리와 팔목을 운동하자고 제안한다. #Person1#은 그것이 너무 늦었다고 생각한다. 지미는 동의한다.                                                \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 #Person1#에게 과일, 채소, 그리고 닭고기를 먹는 것을 권장한다.                                                 \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에 가서 다리와 팔목을 운동하자고 제안한다. #Person1#은 동의한다.                                                             \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 것을 제안한다.                                                    \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 운동하자고 제안한다. #Person1#은 그에게 주간 스케줄을 따르라고 요청한다.                                                          \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 것을 제안한다.                                                    \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 운동하자고 제안한다. #Person1#은 그에게 일주일 스케줄을 따르라고 요청한다.                                                          \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 것을 제안한다.                                                    \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 만나자고 제안한다. #Person1#은 그를 설득하여 3시 30분에 만나기로 한다.                                                       \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 생각한다. #Person2#는 #Person1#에게 과일, 채소, 그리고 닭고기를 먹는 것을 권장한다.                                                 \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 #Person1#을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 것이다.                                                \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 만나자고 제안한다. #Person1#은 그에게 일주일 스케줄을 따르라고 요청한다.                                                           \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 #Person1#에게 과일, 채소, 그리고 닭고기를 먹는 것을 권장한다.                                                 \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 만나자고 제안한다. #Person1#은 그에게 주간 스케줄을 따르라고 요청한다.                                                           \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 #Person2#에게 말한다. #Person2#는 과일, 채소, 그리고 닭고기를 먹는 편이다.                                                     \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 숨쉬기가 힘들고 가슴이 무겁게 느껴진다고 #Person2#에게 말한다. #Person2#는 천식에 대한 검사를 받게 할 것이다.                                                          \n",
      "GOLD: #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다.                                                            \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  지미는 #Person1#에게 3시 30분에 헬스장에서 만나자고 제안한다. #Person1#은 그에게 일주일 동안 운동을 하지 말라고 경고한다.                                                        \n",
      "GOLD: #Person1#은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1#은 건강에 해로운 음식을 먹는 것을 중단해야 한다고 생각한다. #Person2#는 #Person1#에게 과일, 채소, 그리고 닭고기를 먹는 것을 권장한다.                                                 \n",
      "GOLD: #Person1#은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2#는 자신의 건강한 레시피를 #Person1#와 공유한다.                                                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed2a74f39df48599a6ceb126ca92b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1051.382 MB of 1051.382 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/rouge-1</td><td>▁▄▅▅▆▆▇▇▇███████████</td></tr><tr><td>eval/rouge-2</td><td>▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>eval/rouge-l</td><td>▁▄▅▅▆▆▇▇▇███████████</td></tr><tr><td>eval/runtime</td><td>█▄▃▂▃▂▁▁▃▃▂▄▂▁▃▃▁▂▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▁▅▆▇▅▆▇█▆▆▆▅▇█▆▆▇▇▆▆</td></tr><tr><td>eval/steps_per_second</td><td>▁▅▆▇▅▆▇█▆▆▆▅▆█▆▆▇▇▆▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▃▄▅▆▆▇███████████</td></tr><tr><td>train/loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.46957</td></tr><tr><td>eval/rouge-1</td><td>0.31888</td></tr><tr><td>eval/rouge-2</td><td>0.09466</td></tr><tr><td>eval/rouge-l</td><td>0.30851</td></tr><tr><td>eval/runtime</td><td>80.1583</td></tr><tr><td>eval/samples_per_second</td><td>6.225</td></tr><tr><td>eval/steps_per_second</td><td>0.786</td></tr><tr><td>total_flos</td><td>1.8131021060898816e+17</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>20760</td></tr><tr><td>train/grad_norm</td><td>0.79864</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.4257</td></tr><tr><td>train_loss</td><td>1.48024</td></tr><tr><td>train_runtime</td><td>8720.2867</td></tr><tr><td>train_samples_per_second</td><td>142.839</td></tr><tr><td>train_steps_per_second</td><td>11.903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lkk_EXP14</strong> at: <a href='https://wandb.ai/nlp_06/model_selection/runs/k15flmyc' target=\"_blank\">https://wandb.ai/nlp_06/model_selection/runs/k15flmyc</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240523_033330-k15flmyc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습을 위한 tokenizer와 사전 학습된 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    model_name = config['general']['model_name']\n",
    "    configuration = T5Config().from_pretrained(model_name)\n",
    "    # bart_config = BartConfig().from_pretrained(model_name)\n",
    "    # tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "    # bnb_config = BitsAndBytesConfig(\n",
    "    #     load_in_4bit=True,\n",
    "    #     bnb_4bit_use_double_quant=True,\n",
    "    #     bnb_4bit_quant_type=\"nf4\",\n",
    "    #     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    # )\n",
    "\n",
    "    # generate_model = T5ForConditionalGeneration.from_pretrained(config['general']['model_name'],config=bart_config)\n",
    "    # generate_model = T5ForConditionalGeneration.from_pretrained(config['general']['model_name'],config=configuration, quantization_config=bnb_config)\n",
    "    generate_model = T5ForConditionalGeneration.from_pretrained(config['general']['model_name'],config=configuration)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer)) # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "    return generate_model , tokenizer\n",
    "\n",
    "def main(config):\n",
    "    # 사용할 device를 정의합니다.\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # 사용할 모델과 tokenizer를 불러옵니다.\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # 학습에 사용할 데이터셋을 불러옵니다.\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # Trainer 클래스를 불러옵니다.\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    trainer.train()   # 모델 학습을 시작합니다.\n",
    "\n",
    "    # (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : paust/pko-t5-base ----------\n",
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:25<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# 이곳에 내가 사용할 wandb config 설정\n",
    "loaded_config['inference']['ckt_path'] = \"/root/code/checkpoint-17646\"\n",
    "\n",
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset\n",
    "\n",
    "# 추론을 위한 tokenizer와 학습시킨 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "    tokenizer.bos_token = '<s>'\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    # generate_model = BartForConditionalGeneration.from_pretrained(ckt_path)\n",
    "    generate_model = T5ForConditionalGeneration.from_pretrained(ckt_path)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer\n",
    "\n",
    "# 학습된 모델이 생성한 요약문의 출력 결과를 보여줍니다.\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, f\"{exp_name}.csv\"), index=False)\n",
    "\n",
    "    return output\n",
    "\n",
    "# 학습된 모델의 test를 진행합니다.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n"
     ]
    }
   ],
   "source": [
    "print(test.iloc[0]['dialogue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #Person2#는 #Person1#에게 즉시 메시지 프로그램을 사용하는 직원들이 업무 시간 동안 고객과 소통하기 위해 필요하다고 말하고, 모든 내부 통신에 적용될 수 있다고 말합니다.                      \n"
     ]
    }
   ],
   "source": [
    "print(output.iloc[0]['summary'])  # 각 대화문에 대한 요약문이 출력됨을 확인할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

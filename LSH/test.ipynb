{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # 모델의 성능을 평가하기 위한 라이브러리입니다.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # 모델 학습 과정을 손쉽게 Tracking하고, 시각화할 수 있는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Config file 만들기 (선택)\n",
    "- 모델 생성에 필요한 다양한 매개변수 정보를 저장할 수 있습니다.  \n",
    "  따라서, 코드 상에서 모델의 매개변수를 설정할 수도 있지만 독립적인 매개변수 정보 파일을 생성하여 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 설정에 tokenizer 모듈이 사용되므로 미리 tokenizer를 정의해줍니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": \"./\" # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 50,\n",
    "        \"per_device_eval_batch_size\": 32,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (선택) wandb를 사용할 때 설정합니다.\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"nlp_06\",\n",
    "        \"project\": \"sh_test\",\n",
    "        \"name\": \"shlee6630\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # 사전 학습이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Configuration 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': 'data/',\n",
      "             'model_name': 'digit82/kobart-summarization',\n",
      "             'output_dir': './'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'ckt_path': 'model ckt path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 100,\n",
      "               'encoder_max_len': 512,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#PassportNumber#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 100,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 32,\n",
      "              'per_device_train_batch_size': 50,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'nlp_06', 'name': 'shlee6630', 'project': 'sh_test'}}\n"
     ]
    }
   ],
   "source": [
    "# 저장된 config 파일을 불러옵니다.\n",
    "config_path = \"./config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': 'data/',\n",
       " 'model_name': 'digit82/kobart-summarization',\n",
       " 'output_dir': './'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험에 쓰일 데이터의 경로, 사용될 모델, 모델의 최종 출력 결과를 저장할 경로에 대해 확인합니다.\n",
    "loaded_config['general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이곳에 사용자가 저장한 데이터 dir 설정하기\n",
    "# loaded_config['general']['data_path'] = \"data_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'decoder_max_len': 100,\n",
       " 'encoder_max_len': 512,\n",
       " 'eos_token': '</s>',\n",
       " 'special_tokens': ['#Person1#',\n",
       "  '#Person2#',\n",
       "  '#Person3#',\n",
       "  '#PhoneNumber#',\n",
       "  '#Address#',\n",
       "  '#PassportNumber#']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리를 하기 위해 tokenization 과정에서 필요한 정보들을 확인합니다.\n",
    "loaded_config['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'early_stopping_patience': 3,\n",
       " 'early_stopping_threshold': 0.001,\n",
       " 'evaluation_strategy': 'epoch',\n",
       " 'fp16': True,\n",
       " 'generation_max_length': 100,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'learning_rate': 1e-05,\n",
       " 'load_best_model_at_end': True,\n",
       " 'logging_dir': './logs',\n",
       " 'logging_strategy': 'epoch',\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'num_train_epochs': 20,\n",
       " 'optim': 'adamw_torch',\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_eval_batch_size': 32,\n",
       " 'per_device_train_batch_size': 50,\n",
       " 'predict_with_generate': True,\n",
       " 'report_to': 'wandb',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 5,\n",
       " 'seed': 42,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 훈련 시 적용될 매개변수를 확인합니다.\n",
    "loaded_config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': 'nlp_06', 'name': 'shlee6630', 'project': 'sh_test'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 과정에 대한 정보를 제공해주는 wandb 설정 내용을 확인합니다.\n",
    "loaded_config['wandb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_config['wandb']['entity'] = \"nlp_06\"\n",
    "loaded_config['wandb']['name'] = \"shlee6630\"\n",
    "loaded_config['wandb']['project'] = \"sh_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'ckt_path': 'model ckt path',\n",
       " 'early_stopping': True,\n",
       " 'generate_max_length': 100,\n",
       " 'no_repeat_ngram_size': 2,\n",
       " 'num_beams': 4,\n",
       " 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
       " 'result_path': './prediction/'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_config['inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 데이터 불러와서 확인해보기\n",
    "- 실험에서 쓰일 데이터를 load하여 데이터의 구조와 내용을 살펴보겠습니다.\n",
    "- Train, dev, test 순서대로 12457, 499, 250개 씩 데이터가 구성되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>train_12455</td>\n",
       "      <td>#Person1#: 실례합니다. 맨체스터 출신의 그린 씨이신가요?\\n#Person2...</td>\n",
       "      <td>탄 링은 흰머리와 수염으로 쉽게 인식되는 그린 씨를 만나 호텔로 데려갈 예정입니다....</td>\n",
       "      <td>누군가를 태우다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>train_12456</td>\n",
       "      <td>#Person1#: 이윙 씨가 우리가 컨퍼런스 센터에 오후 4시에 도착해야 한다고 ...</td>\n",
       "      <td>#Person1#과 #Person2#는 이윙 씨가 늦지 않도록 요청했기 때문에 컨퍼...</td>\n",
       "      <td>컨퍼런스 센터</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>train_12457</td>\n",
       "      <td>#Person1#: 오늘 어떻게 도와드릴까요?\\n#Person2#: 차를 빌리고 싶...</td>\n",
       "      <td>#Person2#는 #Person1#의 도움으로 5일 동안 소형 차를 빌립니다.</td>\n",
       "      <td>차 렌트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>train_12458</td>\n",
       "      <td>#Person1#: 오늘 좀 행복해 보이지 않아. 무슨 일 있어?\\n#Person2...</td>\n",
       "      <td>#Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 ...</td>\n",
       "      <td>실직</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...</td>\n",
       "      <td>#Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...</td>\n",
       "      <td>짐 싸기</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fname                                           dialogue  \\\n",
       "12452  train_12455  #Person1#: 실례합니다. 맨체스터 출신의 그린 씨이신가요?\\n#Person2...   \n",
       "12453  train_12456  #Person1#: 이윙 씨가 우리가 컨퍼런스 센터에 오후 4시에 도착해야 한다고 ...   \n",
       "12454  train_12457  #Person1#: 오늘 어떻게 도와드릴까요?\\n#Person2#: 차를 빌리고 싶...   \n",
       "12455  train_12458  #Person1#: 오늘 좀 행복해 보이지 않아. 무슨 일 있어?\\n#Person2...   \n",
       "12456  train_12459  #Person1#: 엄마, 다음 토요일에 이 삼촌네 가족을 방문하기 위해 비행기를 ...   \n",
       "\n",
       "                                                 summary     topic  \n",
       "12452  탄 링은 흰머리와 수염으로 쉽게 인식되는 그린 씨를 만나 호텔로 데려갈 예정입니다....  누군가를 태우다  \n",
       "12453  #Person1#과 #Person2#는 이윙 씨가 늦지 않도록 요청했기 때문에 컨퍼...   컨퍼런스 센터  \n",
       "12454       #Person2#는 #Person1#의 도움으로 5일 동안 소형 차를 빌립니다.      차 렌트  \n",
       "12455  #Person2#의 엄마가 일자리를 잃었다. #Person2#는 엄마가 우울해하지 ...        실직  \n",
       "12456  #Person1#은 다음 토요일에 이 삼촌네를 방문할 때 가방을 어떻게 싸야 할지 ...      짐 싸기  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>dev_495</td>\n",
       "      <td>#Person1#: 이제 새해가 되어서 새로운 시작을 하려고 결심했어. \\r\\n#P...</td>\n",
       "      <td>#Person1#은 새해에 금연을 하고 커밍아웃하기로 결정했습니다. #Person2...</td>\n",
       "      <td>새해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dev_496</td>\n",
       "      <td>#Person1#: 너, 조랑 결혼했지? \\r\\n#Person2#: 조? 무슨 말인...</td>\n",
       "      <td>#Person1#은 #Person2#가 조와 결혼했다고 생각했다. #Person2#...</td>\n",
       "      <td>사랑에 빠지다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev_497</td>\n",
       "      <td>#Person1#: 무엇을 도와드릴까요, 부인?\\r\\n#Person2#: 몇 주 동...</td>\n",
       "      <td>#Person2#의 차에서 이상한 소리가 납니다. #Person1#는 브레이크를 교...</td>\n",
       "      <td>소음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev_498</td>\n",
       "      <td>#Person1#: 안녕하세요, 아마존 고객 서비스입니다. 무엇을 도와드릴까요?\\n...</td>\n",
       "      <td>#Person2#님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지...</td>\n",
       "      <td>빠진 페이지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev_499</td>\n",
       "      <td>#Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...</td>\n",
       "      <td>#Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...</td>\n",
       "      <td>여름 휴가</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname                                           dialogue  \\\n",
       "494  dev_495  #Person1#: 이제 새해가 되어서 새로운 시작을 하려고 결심했어. \\r\\n#P...   \n",
       "495  dev_496  #Person1#: 너, 조랑 결혼했지? \\r\\n#Person2#: 조? 무슨 말인...   \n",
       "496  dev_497  #Person1#: 무엇을 도와드릴까요, 부인?\\r\\n#Person2#: 몇 주 동...   \n",
       "497  dev_498  #Person1#: 안녕하세요, 아마존 고객 서비스입니다. 무엇을 도와드릴까요?\\n...   \n",
       "498  dev_499  #Person1#: 여름이 다 되어간다는 게 믿기지 않아.\\r\\n#Person2#:...   \n",
       "\n",
       "                                               summary    topic  \n",
       "494  #Person1#은 새해에 금연을 하고 커밍아웃하기로 결정했습니다. #Person2...       새해  \n",
       "495  #Person1#은 #Person2#가 조와 결혼했다고 생각했다. #Person2#...  사랑에 빠지다  \n",
       "496  #Person2#의 차에서 이상한 소리가 납니다. #Person1#는 브레이크를 교...       소음  \n",
       "497  #Person2#님이 아마존 고객 서비스에 전화하여 아마존에서 받은 책에 한 페이지...   빠진 페이지  \n",
       "498  #Person2#는 #Person1#에게 여름 휴가 동안 파티를 도와주는 회사에서 ...    여름 휴가  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config에 저장된 데이터 경로를 통해 train과 validation data를 불러옵니다.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train data의 구조와 내용을 확인합니다.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "display(train_df.tail())\n",
    "print()\n",
    "\n",
    "# os.path.join(data_path,'train.csv')\n",
    "\n",
    "# validation data의 구조와 내용을 확인합니다.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 가공 및 데이터셋 클래스 구축\n",
    "- csv file 을 불러와서 encoder 와 decoder의 입력형태로 가공해줍니다.\n",
    "- 가공된 데이터를 torch dataset class 로 구축하여 모델에 입력가능한 형태로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리를 위한 클래스로, 데이터셋을 데이터프레임으로 변환하고 인코더와 디코더의 입력을 생성합니다.\n",
    "class Preprocess:\n",
    "    def __init__(self, bos_token: str,  eos_token: str,) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # 실험에 필요한 컬럼을 가져옵니다.\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    # BART 모델의 입력, 출력 형태를 맞추기 위해 전처리를 진행합니다.\n",
    "    def make_input(self, dataset,is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truth를 디코더의 input으로 사용하여 학습합니다.\n",
    "            decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validation에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Test에 사용되는 Dataset 클래스를 정의합니다.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validation에 대해 각각 데이터프레임을 구축합니다.\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trainer 및 Trainingargs 구축하기\n",
    "- Huggingface 의 Trainer 와 Training arguments를 활용하여 모델 학습을 일괄적으로 처리해주는 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능에 대한 평가 지표를 정의합니다. 본 대회에서는 ROUGE 점수를 통해 모델의 성능을 평가합니다.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # 정확한 평가를 위해 미리 정의된 불필요한 생성토큰들을 제거합니다.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # 최종적인 ROUGE 점수를 계산합니다.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE 점수 중 F-1 score를 통해 평가합니다.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 trainer 클래스와 매개변수를 정의합니다.\n",
    "def load_trainer_for_train(config,generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset):\n",
    "    print('-'*10, 'Make training arguments', '-'*10,)\n",
    "    # set training args\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "                output_dir=config['general']['output_dir'], # model output directory\n",
    "                overwrite_output_dir=config['training']['overwrite_output_dir'],\n",
    "                num_train_epochs=config['training']['num_train_epochs'],  # total number of training epochs\n",
    "                learning_rate=config['training']['learning_rate'], # learning_rate\n",
    "                per_device_train_batch_size=config['training']['per_device_train_batch_size'], # batch size per device during training\n",
    "                per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],# batch size for evaluation\n",
    "                warmup_ratio=config['training']['warmup_ratio'],  # number of warmup steps for learning rate scheduler\n",
    "                weight_decay=config['training']['weight_decay'],  # strength of weight decay\n",
    "                lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "                optim =config['training']['optim'],\n",
    "                gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],\n",
    "                evaluation_strategy=config['training']['evaluation_strategy'], # evaluation strategy to adopt during training\n",
    "                save_strategy =config['training']['save_strategy'],\n",
    "                save_total_limit=config['training']['save_total_limit'], # number of total save model.\n",
    "                fp16=config['training']['fp16'],\n",
    "                load_best_model_at_end=config['training']['load_best_model_at_end'], # 최종적으로 가장 높은 점수 저장\n",
    "                seed=config['training']['seed'],\n",
    "                logging_dir=config['training']['logging_dir'], # directory for storing logs\n",
    "                logging_strategy=config['training']['logging_strategy'],\n",
    "                predict_with_generate=config['training']['predict_with_generate'], #To use BLEU or ROUGE score\n",
    "                generation_max_length=config['training']['generation_max_length'],\n",
    "                do_train=config['training']['do_train'],\n",
    "                do_eval=config['training']['do_eval'],\n",
    "                report_to=config['training']['report_to'] # (선택) wandb를 사용할 때 설정합니다.\n",
    "            )\n",
    "\n",
    "    # (선택) 모델의 학습 과정을 추적하는 wandb를 사용하기 위해 초기화 해줍니다.\n",
    "    wandb.init(\n",
    "        entity=config['wandb']['entity'],\n",
    "        project=config['wandb']['project'],\n",
    "        name=config['wandb']['name'],\n",
    "    )\n",
    "\n",
    "    # (선택) 모델 checkpoint를 wandb에 저장하도록 환경 변수를 설정합니다.\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    os.environ[\"WANDB_WATCH\"]=\"false\"\n",
    "\n",
    "    # Validation loss가 더 이상 개선되지 않을 때 학습을 중단시키는 EarlyStopping 기능을 사용합니다.\n",
    "    MyCallback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=config['training']['early_stopping_patience'],\n",
    "        early_stopping_threshold=config['training']['early_stopping_threshold']\n",
    "    )\n",
    "    print('-'*10, 'Make training arguments complete', '-'*10,)\n",
    "    print('-'*10, 'Make trainer', '-'*10,)\n",
    "\n",
    "    # Trainer 클래스를 정의합니다.\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=generate_model, # 사용자가 사전 학습하기 위해 사용할 모델을 입력합니다.\n",
    "        args=training_args,\n",
    "        train_dataset=train_inputs_dataset,\n",
    "        eval_dataset=val_inputs_dataset,\n",
    "        compute_metrics = lambda pred: compute_metrics(config,tokenizer, pred),\n",
    "        callbacks = [MyCallback]\n",
    "    )\n",
    "    print('-'*10, 'Make trainer complete', '-'*10,)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 tokenizer와 사전 학습된 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_train(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "    print('-'*10, f'Model Name : {config[\"general\"][\"model_name\"]}', '-'*10,)\n",
    "    model_name = config['general']['model_name']\n",
    "    bart_config = BartConfig().from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(config['general']['model_name'],config=bart_config)\n",
    "\n",
    "    special_tokens_dict={'additional_special_tokens':config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model.resize_token_embeddings(len(tokenizer)) # 사전에 special token을 추가했으므로 재구성 해줍니다.\n",
    "    generate_model.to(device)\n",
    "    print(generate_model.config)\n",
    "\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 학습하기\n",
    "- 앞에서 구축한 클래스 및 함수를 활용하여 학습 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # 사용할 device를 정의합니다.\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # 사용할 모델과 tokenizer를 불러옵니다.\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_train(config,device)\n",
    "    print('-'*10,\"tokenizer special tokens : \",tokenizer.special_tokens_map,'-'*10)\n",
    "\n",
    "    # 학습에 사용할 데이터셋을 불러옵니다.\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token']) # decoder_start_token: str, eos_token: str\n",
    "    data_path = config['general']['data_path']\n",
    "    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config,preprocessor, data_path, tokenizer)\n",
    "\n",
    "    # Trainer 클래스를 불러옵니다.\n",
    "    trainer = load_trainer_for_train(config, generate_model,tokenizer,train_inputs_dataset,val_inputs_dataset)\n",
    "    trainer.train()   # 모델 학습을 시작합니다.\n",
    "\n",
    "    # (선택) 모델 학습이 완료된 후 wandb를 종료합니다.\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : digit82/kobart-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartConfig {\n",
      "  \"_name_or_path\": \"digit82/kobart-summarization\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30006\n",
      "}\n",
      "\n",
      "---------- Load tokenizer & model complete ----------\n",
      "---------- tokenizer special tokens :  {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': ['#PassportNumber#', '#Person2#', '#Address#', '#Person1#', '#PhoneNumber#', '#Person3#']} ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " #Person1#: 안녕하세요, 스미스씨. 저는 호킨스 의사입니다. 오늘 왜 오셨나요?\n",
      "#Person2#: 건강검진을 받는 것이 좋을 것 같아서요.\n",
      "#Person1#: 그렇군요, 당신은 5년 동안 건강검진을 받지 않았습니다. 매년 받아야 합니다.\n",
      "#Person2#: 알고 있습니다. 하지만 아무 문제가 없다면 왜 의사를 만나러 가야 하나요?\n",
      "#Person1#: 심각한 질병을 피하는 가장 좋은 방법은 이를 조기에 발견하는 것입니다. 그러니 당신의 건강을 위해 최소한 매년 한 번은 오세요.\n",
      "#Person2#: 알겠습니다.\n",
      "#Person1#: 여기 보세요. 당신의 눈과 귀는 괜찮아 보입니다. 깊게 숨을 들이쉬세요. 스미스씨, 담배 피우시나요?\n",
      "#Person2#: 네.\n",
      "#Person1#: 당신도 알다시피, 담배는 폐암과 심장병의 주요 원인입니다. 정말로 끊으셔야 합니다. \n",
      "#Person2#: 수백 번 시도했지만, 습관을 버리는 것이 어렵습니다.\n",
      "#Person1#: 우리는 도움이 될 수 있는 수업과 약물들을 제공하고 있습니다. 나가기 전에 더 많은 정보를 드리겠습니다.\n",
      "#Person2#: 알겠습니다, 감사합니다, 의사선생님.\n",
      "train_label:\n",
      " 스미스씨가 건강검진을 받고 있고, 호킨스 의사는 매년 건강검진을 받는 것을 권장합니다. 호킨스 의사는 스미스씨가 담배를 끊는 데 도움이 될 수 있는 수업과 약물에 대한 정보를 제공할 것입니다.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " #Person1#: 안녕하세요, 오늘 하루 어떠셨어요? \n",
      "#Person2#: 요즘 숨쉬기가 좀 힘들어요.\n",
      "#Person1#: 최근에 감기 같은 것에 걸리신 적이 있나요?\n",
      "#Person2#: 아니요, 감기는 아니에요. 그냥 숨을 쉴 때마다 가슴이 무겁게 느껴져요.\n",
      "#Person1#: 알고 있는 알레르기가 있나요?\n",
      "#Person2#: 아니요, 알고 있는 알레르기는 없어요.\n",
      "#Person1#: 이런 증상이 항상 나타나나요, 아니면 활동할 때 주로 나타나나요?\n",
      "#Person2#: 운동을 할 때 많이 나타나요.\n",
      "#Person1#: 저는 당신을 폐 전문의에게 보내서 천식에 대한 검사를 받게 할 거예요.\n",
      "#Person2#: 도와주셔서 감사합니다, 의사 선생님.\n",
      "val_label:\n",
      " #Person2#는 숨쉬기에 어려움을 겪는다. 의사는 #Person1#에게 이에 대해 묻고, #Person2#를 폐 전문의에게 보낼 예정이다. \n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshlee6630\u001b[0m (\u001b[33mnlp_06\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "---------- Make training arguments ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/upstage_nlp/upstage-nlp-summarization-nlp-06/LSH/wandb/run-20240522_202757-7ux6ko0k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nlp_06/sh_test/runs/7ux6ko0k' target=\"_blank\">shlee6630</a></strong> to <a href='https://wandb.ai/nlp_06/sh_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nlp_06/sh_test' target=\"_blank\">https://wandb.ai/nlp_06/sh_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nlp_06/sh_test/runs/7ux6ko0k' target=\"_blank\">https://wandb.ai/nlp_06/sh_test/runs/7ux6ko0k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make training arguments complete ----------\n",
      "---------- Make trainer ----------\n",
      "---------- Make trainer complete ----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2750' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2750/5000 20:14 < 16:34, 2.26 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>2.478954</td>\n",
       "      <td>0.219738</td>\n",
       "      <td>0.044417</td>\n",
       "      <td>0.211058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.244900</td>\n",
       "      <td>0.630615</td>\n",
       "      <td>0.350850</td>\n",
       "      <td>0.115069</td>\n",
       "      <td>0.333555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.579976</td>\n",
       "      <td>0.369647</td>\n",
       "      <td>0.132539</td>\n",
       "      <td>0.355420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.569139</td>\n",
       "      <td>0.371996</td>\n",
       "      <td>0.131264</td>\n",
       "      <td>0.357378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.501800</td>\n",
       "      <td>0.563602</td>\n",
       "      <td>0.376234</td>\n",
       "      <td>0.139504</td>\n",
       "      <td>0.361327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.478300</td>\n",
       "      <td>0.560637</td>\n",
       "      <td>0.376207</td>\n",
       "      <td>0.135686</td>\n",
       "      <td>0.359999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.376120</td>\n",
       "      <td>0.138334</td>\n",
       "      <td>0.359390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.559232</td>\n",
       "      <td>0.383935</td>\n",
       "      <td>0.142901</td>\n",
       "      <td>0.367752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.561592</td>\n",
       "      <td>0.380221</td>\n",
       "      <td>0.140723</td>\n",
       "      <td>0.364367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.564196</td>\n",
       "      <td>0.375290</td>\n",
       "      <td>0.136671</td>\n",
       "      <td>0.358936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.563218</td>\n",
       "      <td>0.380508</td>\n",
       "      <td>0.142531</td>\n",
       "      <td>0.365587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는#Person2##Person2# 는 감기 같은 감기에 걸리신 적이 있나하면, #Person2# 는 감기 같은 증상이 항상 나타나고, 활동할 때 주로 나타나며, #Person2# 는 감기에 대한 검사를 받게 할 것입니다.                                                         \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은#Person1#은 #Person1#에게 #Person1#에게 #Person1#에게 #Person1#에게 #Person1#에게 #Person1#에게 #Person1#에게 #Person1# 에게 #Person1#에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# 에게 #Person1# \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person1# 은 #Person2# 에게 #Person1# 의 건강에 해로운 음식을 먹는 것을 멈춰 달라고 말합니다.                                                                             \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 감기 같은 것에 걸리셨습니다. #Person1# 은 #Person2# 에게 알레르기가 있다고 말합니다.                                                                            \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 #Person1# 의 주간 스케줄을 바꾸라고 제안한다.                                                                                   \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹지 말라고 말합니다. #Person2# 는 닭고기를 좋아합니다.                                                                         \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 감기 같은 것에 걸리셨지만 #Person1# 는 감기라고 말합니다. #Person1# 는 #Person2# 에게 천식에 대한 검사를 받게 할 것입니다.                                                                   \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 지미에게 오후 3시 30분에 헬스장에서 만나자고 제안한다.                                                                                   \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아한다.                                                                        \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 감기에 걸렸습니다. #Person1# 은 #Person2# 에게 천식에 대한 검사를 받게 할 것입니다.                                                                              \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 오후에 운동하자고 제안한다. #Person1# 은 #Person2# 에게 주간 스케줄을 따르라고 제안한다.                                                                         \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 과 #Person2# 는 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 생각합니다. #Person1# 은 닭고기를 좋아합니다.                                                                           \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 감기에 걸렸지만, #Person1# 는 천식에 대한 검사를 받을 예정입니다.                                                                                  \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 금요일에 운동하자고 제안한다. #Person1# 은 동의한다.                                                                                  \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아한다.                                                                        \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 숨쉬기가 좀 힘들고 천식에 대한 검사를 받을 예정입니다.                                                                                    \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 운동하러 가자고 제안하지만, #Person1# 은 주간 스케줄을 따르고 있어서 #Person1# 은 #Person2# 에게 두 날을 바꾸라고 요청한다.                                                                 \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 과 #Person2# 는 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 생각합니다. 그들은 닭고기를 먹는 것에 동의합니다.                                                                           \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 숨쉬기가 좀 힘들고 천식에 대한 검사를 받게 될 것입니다.                                                                           \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 운동하러 가자고 제안하지만, #Person1# 은 주간 스케줄을 따르고 있어서 #Person1# 은 두 날을 바꾸기로 결정한다.                                                            \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아한다.                                                               \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 숨쉬기가 좀 힘들고 천식이 의심됩니다. #Person1# 은 #Person2# 에게 천식에 대한 검사를 받게 할 것입니다.                                                              \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 지미에게 운동 시간을 달라고 요청한다. 지미는 동의한다. 그들은 오후에 운동할 예정이다.                                                                    \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아한다.                                                              \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 숨쉬기가 좀 힘들고 천식이 의심됩니다. #Person1# 은 #Person2# 에게 천식에 대한 검사를 받게 할 것입니다.                                                                      \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 금요일에 운동하자고 제안하지만, #Person1# 은 주간 스케줄을 따르고 있다.                                                                            \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아한다.                                                                      \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 숨쉬기가 좀 힘들고 천식에 대한 검사를 받게 될 것입니다.                                                                                    \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   지미는 #Person1# 에게 금요일에 운동하자고 제안하지만, #Person1# 은 주간 스케줄을 따르고 있다.                                                                              \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아한다.                                                                        \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# 는 숨쉬기가 좀 힘들고 천식에 대한 검사를 받게 될 것입니다.                                                                         \n",
      "GOLD: #Person2# 는 숨쉬기에 어려움을 겪는다. 의사는 #Person1# 에게 이에 대해 묻고, #Person2# 를 폐 전문의에게 보낼 예정이다.                                                              \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 지미에게 운동 시간을 변경해달라고 요청한다. 지미는 동의한다.                                                                        \n",
      "GOLD: #Person1# 은 지미에게 운동하러 가자고 제안하고 팔과 배를 운동하도록 설득한다.                                                                        \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# 은 #Person2# 에게 더 이상 건강에 해로운 음식을 먹는 것을 멈춰야 한다고 말한다. #Person2# 는 닭고기를 좋아하며, #Person1# 은 닭고기를 좋아한다.                                                     \n",
      "GOLD: #Person1# 은 건강에 해로운 음식을 먹는 것을 멈추려는 계획을 세우고, #Person2# 는 자신의 건강한 레시피를 #Person1# 와 공유한다.                                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff1c2dde4864a7d84200f061ac106cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='472.661 MB of 472.661 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/rouge-1</td><td>▁▇▇▇███████</td></tr><tr><td>eval/rouge-2</td><td>▁▆▇▇█▇█████</td></tr><tr><td>eval/rouge-l</td><td>▁▆▇████████</td></tr><tr><td>eval/runtime</td><td>█▁▂▃▂▄▂▁▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▁█▆▅▆▅▇█▇▆▇</td></tr><tr><td>eval/steps_per_second</td><td>▁█▆▅▆▅▇█▇▆▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁███▇▆▆▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.56322</td></tr><tr><td>eval/rouge-1</td><td>0.38051</td></tr><tr><td>eval/rouge-2</td><td>0.14253</td></tr><tr><td>eval/rouge-l</td><td>0.36559</td></tr><tr><td>eval/runtime</td><td>9.456</td></tr><tr><td>eval/samples_per_second</td><td>52.771</td></tr><tr><td>eval/steps_per_second</td><td>1.692</td></tr><tr><td>train/epoch</td><td>11.0</td></tr><tr><td>train/global_step</td><td>2750</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.3991</td></tr><tr><td>train/total_flos</td><td>4.177517883162624e+16</td></tr><tr><td>train/train_loss</td><td>1.01269</td></tr><tr><td>train/train_runtime</td><td>1211.5141</td></tr><tr><td>train/train_samples_per_second</td><td>205.643</td></tr><tr><td>train/train_steps_per_second</td><td>4.127</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">shlee6630</strong> at: <a href='https://wandb.ai/nlp_06/sh_test/runs/7ux6ko0k' target=\"_blank\">https://wandb.ai/nlp_06/sh_test/runs/7ux6ko0k</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240522_202757-7ux6ko0k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 추론하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_config['inference']['ckt_path'] = \"checkpoint-2750\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization 과정까지 진행된 최종적으로 모델에 입력될 데이터를 출력합니다.\n",
    "def prepare_dev_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    test_file_path = os.path.join(config['general']['data_path'],'dev.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론을 위한 tokenizer와 학습시킨 모델을 불러옵니다.\n",
    "def load_tokenizer_and_model_for_test(config,device):\n",
    "    print('-'*10, 'Load tokenizer & model', '-'*10,)\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    ckt_path = config['inference']['ckt_path']\n",
    "    print('-'*10, f'Model Name : {model_name}', '-'*10,)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    generate_model = BartForConditionalGeneration.from_pretrained(ckt_path)\n",
    "    generate_model.resize_token_embeddings(len(tokenizer))\n",
    "    generate_model.to(device)\n",
    "    print('-'*10, 'Load tokenizer & model complete', '-'*10,)\n",
    "\n",
    "    return generate_model , tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델이 생성한 요약문의 출력 결과를 보여줍니다.\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # 정확한 평가를 위하여 노이즈에 해당되는 스페셜 토큰을 제거합니다.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = summary.copy()\n",
    "    for token in remove_tokens:\n",
    "        preprocessed_summary = [sentence.replace(token,\" \") for sentence in preprocessed_summary]\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"test_output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : digit82/kobart-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:23<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.0\n",
      "---------- Load tokenizer & model ----------\n",
      "---------- Model Name : digit82/kobart-summarization ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "#Person1#: 더슨 씨, 받아쓰기 좀 해주세요. \n",
      "#Person2#: 네, 실장님...\n",
      "#Person1#: 이것은 오늘 오후까지 모든 직원에게 내부 메모로 전달되어야 합니다. 준비되셨나요?\n",
      "#Person2#: 네, 실장님. 시작하셔도 됩니다.\n",
      "#Person1#: 모든 직원들에게 주의하라... 즉시 효력을 발휘하여, 모든 사무실 통신은 이메일 통신과 공식 메모로 제한됩니다. 근무 시간 동안 직원들이 즉시 메시지 프로그램을 사용하는 것은 엄격히 금지됩니다.\n",
      "#Person2#: 실장님, 이것은 내부 통신에만 적용되는 건가요? 아니면 외부 통신에도 제한이 되는 건가요?\n",
      "#Person1#: 이것은 모든 통신에 적용되어야 합니다, 이 사무실 내의 직원들 사이뿐만 아니라 외부 통신에도 마찬가지입니다.\n",
      "#Person2#: 하지만 실장님, 많은 직원들이 고객과 소통하기 위해 즉시 메시지를 사용하고 있습니다.\n",
      "#Person1#: 그들은 그들의 의사소통 방법을 바꾸어야만 합니다. 이 사무실에서 누구도 즉시 메시지를 사용하지 않기를 원합니다. 너무 많은 시간을 낭비하게 됩니다! 이제, 메모를 계속해주세요. 우리가 어디까지 했나요?\n",
      "#Person2#: 이것은 내부와 외부 통신에 적용됩니다.\n",
      "#Person1#: 그렇습니다. 즉시 메시지를 계속 사용하는 어떤 직원이라도 먼저 경고를 받고 직무 정지에 처해질 것입니다. 두 번째 위반 시에는 직원은 해고에 처해질 것입니다. 이 새로운 정책에 대한 어떤 질문이라도 부서장에게 직접 문의하면 됩니다.\n",
      "#Person2#: 그게 다신가요?\n",
      "#Person1#: 네. 이 메모를 오후 4시 전에 모든 직원에게 타이핑하여 배포해 주세요.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:23<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델의 test를 진행합니다.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)\n",
    "    output2 = test_inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>더슨 씨는 #Person1# 에게 모든 사무실 통신이 이메일 통신과 공식 메모로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>#Person1# 은 교통 체증에 걸렸다. #Person2# 는 #Person1#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>케이트는 마샤와 히어로가 이혼을 신청했다고 #Person1# 에게 말한다. 그녀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>브라이언은 #Person1# 에게 자신의 생일을 축하하기 위해 파티에 왔다고 말...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person2# 는 #Person1# 에게 올림픽 스타디움에 5000개의 좌석이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>찰리는 아빠를 데리러 가야하기 때문에 새 게임에 대해 잭에게 이야기한다. 잭은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>#Person2# 는 #Person1# 에게 #Person2# 가 컨트리 음악에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>앨리스는 #Person1# 에게 기계를 어떻게 사용하는지 알려주고, 기계가 너무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>스티브는 계약이 다음 달에 끝나기 때문에 새 집을 찾고 있다. 매튜는 그녀의 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>벳시는 승진하고 친구들 모두를 위한 큰 파티를 열려고 한다. 프랭크는 파티에 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0    더슨 씨는 #Person1# 에게 모든 사무실 통신이 이메일 통신과 공식 메모로...\n",
       "1      test_1   #Person1# 은 교통 체증에 걸렸다. #Person2# 는 #Person1#...\n",
       "2      test_2    케이트는 마샤와 히어로가 이혼을 신청했다고 #Person1# 에게 말한다. 그녀...\n",
       "3      test_3    브라이언은 #Person1# 에게 자신의 생일을 축하하기 위해 파티에 왔다고 말...\n",
       "4      test_4   #Person2# 는 #Person1# 에게 올림픽 스타디움에 5000개의 좌석이...\n",
       "..        ...                                                ...\n",
       "494  test_495    찰리는 아빠를 데리러 가야하기 때문에 새 게임에 대해 잭에게 이야기한다. 잭은 ...\n",
       "495  test_496   #Person2# 는 #Person1# 에게 #Person2# 가 컨트리 음악에 ...\n",
       "496  test_497    앨리스는 #Person1# 에게 기계를 어떻게 사용하는지 알려주고, 기계가 너무...\n",
       "497  test_498    스티브는 계약이 다음 달에 끝나기 때문에 새 집을 찾고 있다. 매튜는 그녀의 이...\n",
       "498  test_499    벳시는 승진하고 친구들 모두를 위한 큰 파티를 열려고 한다. 프랭크는 파티에 1...\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output  # 각 대화문에 대한 요약문이 출력됨을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
